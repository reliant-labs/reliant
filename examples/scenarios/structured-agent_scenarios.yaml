# Test scenarios for structured-agent.yaml workflow
#
# Structured Agent workflow structure:
# - agent_loop (main loop) contains: call_llm -> remind_response -> approval -> execute_tools -> compact
# - Loop continues while: response tool NOT called AND iteration < max_turns
# - Requires LLM to call a response tool (default: submit_response) to complete
#
# Key behaviors:
# - If LLM responds without tool calls, remind_response tells it to use the response tool
# - mode=auto: auto-approves tool execution (skips approval node)
# - mode=manual: requires approval before tool execution
# - Response tool output is captured as structured data via response_data

---
# Happy path: LLM immediately calls the response tool
name: response_tool_called
description: LLM calls the response tool immediately, loop completes
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
events:
  # LLM calls the response tool directly
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I've completed the analysis."
      response_text: "I've completed the analysis."
      tool_calls:
        - id: call_0
          name: submit_response
          input:
            choice: complete
            value: "The task has been completed successfully. Analysis shows no issues."
  # Response tool executes - response_data is populated
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: '{"choice": "complete", "value": "The task has been completed successfully."}'
      response_data:
        submit_response:
          choice: complete
          value: "The task has been completed successfully. Analysis shows no issues."
      thread_token_count: 500
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.remind_response
    - agent_loop.approval
    - agent_loop.compact

---
# LLM uses regular tools first, then calls response tool
name: tools_then_response
description: LLM uses regular tools to gather information, then calls response tool
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
events:
  # First iteration: LLM reads a file
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me read the configuration file first."
      response_text: "Let me read the configuration file first."
      tool_calls:
        - id: call_0
          name: view
          input:
            file_path: "config.yaml"
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: "database:\n  host: localhost\n  port: 5432"
      thread_token_count: 500
  # Second iteration: LLM searches for more info
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me check for any related files."
      response_text: "Let me check for any related files."
      tool_calls:
        - id: call_1
          name: grep
          input:
            pattern: "database"
            path: "."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_1
          content: '["config.yaml", "db/connection.go"]'
      thread_token_count: 600
  # Third iteration: LLM submits structured response
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Analysis complete."
      response_text: "Analysis complete."
      tool_calls:
        - id: call_2
          name: submit_response
          input:
            choice: complete
            value: "Database is configured for localhost:5432. Found 2 related files."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_2
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "Database is configured for localhost:5432. Found 2 related files."
      thread_token_count: 700
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.remind_response
    - agent_loop.approval

---
# LLM tries to end without tools, gets reminded, then calls response tool
name: reminder_then_response
description: LLM responds without tools, gets reminder, then calls response tool
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
events:
  # First iteration: LLM responds with text only (no tool calls)
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I've reviewed the request and here's my analysis."
      response_text: "I've reviewed the request and here's my analysis."
      tool_calls: []
  # remind_response node executes (no tool calls triggers this edge)
  # Loop continues because response tool wasn't called (completed != true)

  # Second iteration: LLM now calls the response tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me submit my response properly."
      response_text: "Let me submit my response properly."
      tool_calls:
        - id: call_0
          name: submit_response
          input:
            choice: complete
            value: "Analysis complete. The code follows best practices."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "Analysis complete. The code follows best practices."
      thread_token_count: 500
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.remind_response
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.approval

---
# Manual mode with approval granted
name: manual_mode_approved
description: Manual mode, user approves tool execution
inputs:
  mode: manual
  max_turns: 100
  response_tool_name: submit_response
events:
  # LLM requests a tool in manual mode
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me read the file."
      response_text: "Let me read the file."
      tool_calls:
        - id: call_0
          name: view
          input:
            file_path: "main.go"
  # Approval is required in manual mode
  - node: agent_loop.approval
    output:
      approval_id: "approval_1"
      status: approved
      action_taken: approve
      data: {}
  # Tool executes after approval
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: "package main"
      thread_token_count: 500
  # LLM submits response
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Found a Go file."
      response_text: "Found a Go file."
      tool_calls:
        - id: call_1
          name: submit_response
          input:
            choice: complete
            value: "File contains a Go main package."
  # Approval for response tool
  - node: agent_loop.approval
    output:
      approval_id: "approval_2"
      status: approved
      action_taken: approve
      data: {}
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_1
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "File contains a Go main package."
      thread_token_count: 600
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.approval
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.remind_response

---
# Manual mode with approval denied
name: manual_mode_denied
description: Manual mode, user denies approval, loop continues without executing tools
inputs:
  mode: manual
  max_turns: 100
  response_tool_name: submit_response
events:
  # LLM requests a risky tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I'm going to delete the file."
      response_text: "I'm going to delete the file."
      tool_calls:
        - id: call_0
          name: bash
          input:
            command: "rm -rf /important"
  # Approval is denied
  - node: agent_loop.approval
    output:
      approval_id: "approval_1"
      status: denied
      action_taken: deny
      data: {}
  # Loop continues (denied means no tool execution, but loop still iterates)
  # LLM tries again with response tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I'll submit my response instead."
      response_text: "I'll submit my response instead."
      tool_calls:
        - id: call_1
          name: submit_response
          input:
            choice: complete
            value: "Task completed without file deletion as requested."
  # Approval granted for response tool
  - node: agent_loop.approval
    output:
      approval_id: "approval_2"
      status: approved
      action_taken: approve
      data: {}
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_1
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "Task completed without file deletion as requested."
      thread_token_count: 500
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.approval
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.remind_response

---
# Multiple reminders before LLM gets it right
name: multiple_reminders
description: LLM needs multiple reminders before calling response tool
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
events:
  # First iteration: text only
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Here's what I found."
      response_text: "Here's what I found."
      tool_calls: []
  # remind_response triggers

  # Second iteration: still text only
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me explain further..."
      response_text: "Let me explain further..."
      tool_calls: []
  # remind_response triggers again

  # Third iteration: finally uses response tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Submitting my response now."
      response_text: "Submitting my response now."
      tool_calls:
        - id: call_0
          name: submit_response
          input:
            choice: complete
            value: "Final analysis complete."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "Final analysis complete."
      thread_token_count: 500
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.remind_response
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.approval

---
# Compaction triggered after large tool result
name: compaction_triggered
description: Token count exceeds threshold, compact node runs
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
  compaction_threshold: 1000
events:
  # LLM reads a large file
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Reading the large documentation file."
      response_text: "Reading the large documentation file."
      tool_calls:
        - id: call_0
          name: view
          input:
            file_path: "docs/api.md"
  # Large tool result triggers compaction
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: "Very long documentation content..."
      thread_token_count: 5000
  # Compact runs
  - node: agent_loop.compact
    output:
      message:
        role: assistant
        text: "Context compacted."
  # LLM submits response
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Documentation reviewed."
      response_text: "Documentation reviewed."
      tool_calls:
        - id: call_1
          name: submit_response
          input:
            choice: complete
            value: "API documentation is comprehensive and well-structured."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_1
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "API documentation is comprehensive and well-structured."
      thread_token_count: 1000
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
    - agent_loop.compact
  not_reached:
    - agent_loop.approval
    - agent_loop.remind_response

---
# Compaction skipped when token count is below threshold
name: compaction_skipped_below_threshold
description: Token count stays below compaction_threshold, compact node is not reached
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: submit_response
  compaction_threshold: 185000
events:
  # LLM reads a file
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Reading the file."
      response_text: "Reading the file."
      tool_calls:
        - id: call_0
          name: view
          input:
            file_path: "src/main.go"
  # Tool result with low token count (below threshold)
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: "package main"
      thread_token_count: 500
  # Compact is skipped, LLM submits response
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "File reviewed."
      response_text: "File reviewed."
      tool_calls:
        - id: call_1
          name: submit_response
          input:
            choice: complete
            value: "Simple Go main package."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_1
          content: '{"choice": "complete"}'
      response_data:
        submit_response:
          choice: complete
          value: "Simple Go main package."
      thread_token_count: 600
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.approval
    - agent_loop.remind_response
    - agent_loop.compact

---
# Custom response tool name
name: custom_response_tool_name
description: Workflow uses a custom response tool name
inputs:
  mode: auto
  max_turns: 100
  response_tool_name: finish_task
  response_tool_description: "Complete the task with your findings"
events:
  # LLM calls the custom response tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Task complete."
      response_text: "Task complete."
      tool_calls:
        - id: call_0
          name: finish_task
          input:
            choice: complete
            value: "All items have been verified."
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: '{"choice": "complete"}'
      response_data:
        finish_task:
          choice: complete
          value: "All items have been verified."
      thread_token_count: 500
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.remind_response
    - agent_loop.approval

---
# Max turns without response - loop exits when max_turns reached without response tool being called
name: max_turns_without_response
description: Loop exits when max_turns reached and agent never called response tool
inputs:
  mode: auto
  max_turns: 3
  response_tool_name: submit_response
events:
  # Iteration 1: LLM responds without tools, gets reminded
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I'm thinking about how to approach this."
      response_text: "I'm thinking about how to approach this."
      tool_calls: []
  # remind_response triggers because no tool calls

  # Iteration 2: LLM still doesn't use tools
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me analyze the problem more."
      response_text: "Let me analyze the problem more."
      tool_calls: []
  # remind_response triggers again

  # Iteration 3 (max_turns=3, last iteration): LLM still doesn't use response tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "I need more time to think."
      response_text: "I need more time to think."
      tool_calls: []
  # Loop exits after iteration 3 because iter.iteration (3) is no longer < max_turns (3)
  # Note: completed is never set to true since response tool was never called
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.remind_response
  not_reached:
    - agent_loop.execute_tools
    - agent_loop.approval
