# Auto mode: LLM uses tools, they execute automatically, then responds
name: tool_use_auto_mode
description: LLM calls tools in auto mode, tools execute without approval, loop continues
inputs:
  mode: auto
  max_turns: 100
events:
  # First iteration: LLM requests a tool
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "Let me read that file for you."
      response_text: "Let me read that file for you."
      tool_calls:
        - id: call_0
          name: view
          input:
            file_path: "/path/to/file.go"
  # Tool executes (auto mode skips approval)
  - node: agent_loop.execute_tools
    output:
      message:
        role: tool
        text: ""
      tool_results:
        - tool_call_id: call_0
          content: "package main\n\nfunc main() {\n\tfmt.Println(\"Hello\")\n}"
      thread_token_count: 500
  # Second iteration: LLM responds with final answer
  - node: agent_loop.call_llm
    output:
      message:
        role: assistant
        text: "The file contains a simple Go main package that prints Hello."
      response_text: "The file contains a simple Go main package that prints Hello."
      tool_calls: []
expect:
  outcome: completed
  reached:
    - agent_loop
    - agent_loop.call_llm
    - agent_loop.execute_tools
  not_reached:
    - agent_loop.approval
    - max_turns_notification
